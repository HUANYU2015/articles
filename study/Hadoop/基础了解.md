# 大数据基础

## 大数据带来的技术驱动

* 技术驱动：数据量大
  * 存储：文件存储 ==> 分布式存储
  * 计算：单机 ==> 分布式计算 MapReduce
  * 网络：万兆带宽
  * DB：RDBMS ==> NoSQL(HBase/Redis...)
* 商业驱动：价值驱动

## 大数据现存的模式

* 拥数据，没有大数据思维
* 没有大数据，有大数据思维
* 既有大数据，又有大数据思维

## 大数据的技术概念

* 单机：CPU memory disk
* 分布式并行计算/处理

$过程$

* 数据采集（精细化筛选）：flume Sqoop
* 数据存储：Hadoop
* 数据处理/分析/挖掘：Hadoop、Spark、Flink...
* 可视化：

## 大数据技术架构

* 对现有数据库管理技术的挑战：MySQL->NoSQL
* 经典的数据库技术并没有考虑到数据的多类型
* 实时性的技术挑战
* 网络架构、数据中心、运维的挑战
* 隐私防泄漏
* 数据源复杂多样的挑战

## 如何对大数据进行存储和分析

|系统瓶颈|Google 大数据技术|
|:---:|:---:|
|存储容量|MapReduce|
|读写速度|bigtable|
|计算效率|GFS|

## 大数据典型应用

Count、Sum、AVG -> group by/join -> 窗口分析函数 -> 异常、欺诈检测 -> 人工智能

报表 -> 用户细分 -> 指标监控 -> 指标预警

## 初识Hadoop

### Hadoop 概述

logo 来源于动物，Hadoop 之父是 Doug Cutting。
Hadoop 是 Apache 社区的顶级项目：xxxx.apache.org
hadoop hive hbase spark flink storm

The Apache hadoop project develops open-source software for `reliable, scalable, distributed computing`.

The Apache Hadoop software libary is a framework that allows for the `distributed processing` of large data sets across clusters of computers using simple programming models.

Hadoop 提供`分布式存储 + 分布式计算`，是一个分布式的系统基础架构。

分布式存储：一个文件被拆分成很多块，并且以副本的方式存储在各个节点中。
分布式系统架构：用户可以在不了解分布式底层细节的前提下使用。

### Hadoop 核心组件

* **Hadoop Common**: The common utilities that support the other Hadoop modules.
* **Hadoop Distributed File System(HDFS-分布式文件系统)**: A distributed file system that provides high-throughput access to application data.
* **Hapoop Yarn(分布式资源调度框架)**: A framework for `job scheduling` and `cluster resource management`
* **Hadoop MapReduce(分布式计算框架)**: A Yarn-based system for parallel processing of large data sets
* **Hadoop Ozone(对象存储)**: A object store for Hadoop

#### HDFS-分布式文件系统

* 源于 Google 的 gfs 论文，论文发表与2003年10月
* hdfs 是 gfs 的克隆版
* HDFS 特点：扩展性 & 容错性 & 海量数据存储
* 将文件切分成指定大小(block-size)的`数据块(block)`，并以`多副本(multi-standy)`的方式存储在机器上面
* 数据切分、多副本、容错等操作对用户是透明的(用户无需知晓)

$概述$

The hdfs is a distributed file system designed to run on commodity hardware. It has many simikarities with existing distributed file systems. However, the differences from other distributed file systems are significant. HDFS is highly fault-tolerant and is designed to be deployed on low-cost hardware. HDFS provides high throughput access to application data and is suitable for applications that have large data sets. HDFS relaxes a few POSIX(可移植性操作系统接口) requirements to enable streaming access to file system data.

1. distributed
2. commodity hardware or low-cost hardware
3. fault-tolerant
4. high throughput access
5. large data sets

普通文件系统 vs 分布式文件系统

    单机
    分布式文件系统能够横跨 N 个机器

$HDFS前提和设计目标$

* **Hardware Failure**: Hardware failure is the norm rather than the exception. An HDFS instance may consist of hundreds or thousands of server machines, each storing part of the file system's data. The fact that there are a huge number of components and that each component has a **`non-trivial probability of failure`** means that some component of HDFS is always non-functional(始终不起作用). Therefore, **`detection of faults and quick, automatic recovery from them`** is a core architectural goal of HDFS.

* **Streaming Data Access**: Applications that run on HDFS need **`streaming access`** to their data sets. They are not general purpose applications that typically run on general purpose file systems. HDFS is designed more for **`batch processing`** rather than **`interactive use`** by users. The emphasis is on **`high throughput of data access`** rather than **`low latency of data access`**. POSIX(可移植性操作系统接口) imposes many hard requirements that are not needed for applications that are targeted for HDFS. POSIX semantics in a few areas has been traded to increase data throughput rates.

* **Large Data Sets**: Application that run on HDFS have large data sets. A typical file in HDFS is gigabytes to terabytes in size. Thus, HDFS is tuned(调优的) to support large files. It should provides **`high aggregate data bandwidth(高聚合数据带宽)`** and scale to hundreds of nodes in a single cluster. It should support tens of millions of files in a single instance.

* **Simple Coherency Model**: 简化的数据一致性问题，并实现了高吞吐量数据访问。

* **Moving Computation is Cheaper than Moving Data**: A computation requested by an application is much more efficient if **`it is executed near the data it operates on`**. This is especially true when the size of the data set is huge. This minizes network congestion and increase the overall throughput of system. The assumption is that it is often better to migrate the computation closer to where the data is located rather than moving the data to where the application is running. `HDFS provides interfaces for application to move themselves closer to where the data is located`.

* **Portability(可移植性、便携性) Across Heterogeneous Hardware and Software Platforms**: HDFS has been designed to be portable from one platform to another. This facilitates widespread adoption of HDFS as a platform of choice for a large set of applications.

#### 分布式计算框架-MapReduce

* 源于 Google 的 MapReduce 论文，论文发表于2004年12月
* MapReduce 是 Google MapReduce 的克隆版
* MapReduce 特点：扩展性 & 容错性 & 海量数据离线处理
* word count process: input -> splitting -> mapping -> shuffling -> reducing -> final result

#### 资源调度系统 YARN

* YARN：yet another resource negotiator
* 负责整个`集群资源`的管理和调度
* YARN 特点：扩展性 & 容错性 & `多框架资源`统一调度
* 多框架：script-Pig sql-hive nosql-hbase stream-storm in-memory-spark search-solr flink

### Hadoop 优势

$高可靠性$

* 数据存储：数据库多副本
* 数据计算：重新调度作业计算

$高扩展性$

* 存储、计算资源不够时，可以横向线型扩展机器
* 一个集群中可以包含数以千计的节点
* 存储在廉价的机器上(去 IOE)，降低成本
* 成熟的生态圈

### Hadoop 发展史

诞生于2006年，nutch-gfs-mapreduce-bigtable(hbase)-2007百度移动使用-hive-cloudera-cbh-spark-

### Hadoop 生态系统

**狭义的 Hadoop**：是一个适用于大数据分布式存储（HDFS）、分布式计算（MapReduce）和资源调度（YARN）的平台；

**广义的 Hadoop**：指的是 `Hadoop 的生态系统`，它是一个很庞大的概念，Hadoop 是其中最重要最基础的一个部分；生态系统中的一个子系统`只解决某一特定问题域`（甚至可能很窄）不做统一型的一个全能系统，而是`小而精`的`多个小的系统`；

![Xnip2019-04-24_17-33-22](/assets/Xnip2019-04-24_17-33-22.png)

* 开源、社区活跃
* 囊括了大数据处理的方方面面
* 成熟的生态圈

### Hadoop 发行版的选择

* Apache
  * 优点：纯开源，
  * 缺点：不同版本、不同框架之间整合问题多 jar 冲突...
* CDH
  * 优点：http://www.cloudera.com cm（clouder manager）通过页面一键安装各种框架、进行升级操作，
  * 缺点：cm 不开源
* Hortonworks: HDP 企业通过发布自己的数据平台可以直接基于页面框架进行改造
  * 优点：原装 Hadoop、纯开源、支持 tez(分布式dh框架)
  * 缺点：企业级安全不开源，
* MapReduce

## HDFS Architecture

* NameNode and DataNodes
* master/slave architecture

### 架构概述

HDFS has a **`master/slave`** architecture. An HDFS cluster consists of a single NameNode, a master server that **`manages the file system namespace`** and **`regulates access to files by clients`**.

In addition, there are a number of DataNodes, usually one per node in the cluster, which **`manage storage attached to the nodes`** that they are run on.

HDFS exposes a file system namespace and allows user data to be stored in files. Internally, a file split into one or more blocks and these blocks are stored in a set of DataNodes(一组 DataNode).

**`The NameNode executes file system namespace operations like opening, closing, and renaming files and directories`**. It also determines the mapping of blocks to DataNodes.

**`The DataNodes are responsible for serving read and write requests from the file system's clients. The DataNodes also perform block creation、deletion、and replication upon instruction from the NameNode`**.

A typical deployment has a dedicated(专有的) machine that runs only **`the NameNode software`**. Each of the other machines in the cluster runs **`one instance of the DataNode software`**. The architecture does not preclude(排斥) running multiple DataNodes on the same machine but in a real deployment that is rarely the case.

### The File System Namespace

HDFS supports a traditional hierarchical(层级的) file organization. A user or an application can create directories and store files inside these directories. **`The file system namespace hierarchy is similar to most other existing file systems`**; one can create and remove files, move a file from one directory to another, or rename a file. HDFS supports **user quotas** and **access permissions**. HDFS does not support hard links or soft links. However, the HDFS architecture does not preclude implementing these features.

**`The NameNode maintains the file system namespace. Any change to the file system namespace or its properties is recorded by the HDFS`**. An application can specify the number of replicas of a file that should be maintained by HDFS. The number of copies of a file is called the **replication factor** of that file. This information is stored by the NameNode.

### Data Replication

HDFS is designed to reliably store very **large files** across machines in a large cluster. It stores each file as a sequence of blocks. **The blocks of file are replicated for fault tolerance**. The block size and replication factor are configurable per file.

All blocks in a file except the last block are the same size, while users can start a new block without filling out the last block to the configured block size after the support for variable length block was added to append and hsync.(同时在将对可变长度 block 的支持添加到“append”和“hsync“功能中后，用户可以以一个新的 block 开始而不必将原有最后一个block 填满至配置的容量规格)

An application can specify the number of replicas of a file. The replication factor can be specified at file creation time and can be changed later. Files in HDFS are write-once(except for appends and truncates 除过追加和截断) and have strictly(严格地、确实地) one writer at any time.

The NameNode makes all decisions regarding replication of blocks. It periodically receives a **Heartbeat** and a **Blockreport** from each of the DataNodes in the cluster. Receipt of a Heartbeat implies that the DataNode is functioning properly. A Blockreport contains a list of all blocks on a DataNode.

![hdfsdatanodes](/assets/hdfsdatanodes.png)

## linux 操作

linux 用户名：hadoop
密码：123456
HostName: hadoop000

创建文件夹：
    mkdir software 软件安装包存放位置
    mkdir app      软件安装位置
    mkdir data     数据存放位置
    mkdir lib      存放作业 jar
    mkdir shell    存放相关脚本
    mkdir maven_resp 存放 maven依赖包
hadoop 用户转 root 用户：
    ```sudo -i```
反向
    ```su hadoop```
linux 版本：centos7
    ```uname -a```

配置好 IP 及域名映射：
    ```vim /etc/hosts```
    server ip   hostname

## Hadoop 初始安装配置

下载地址：http://archive.cloudera.com/cdh5/cdh/5/
Hadoop 选择hadoop-2.6.0-cdh5.15.1.tar.gz

使用单机版进项框架学习

Hadoop 安装前置要求安装以下软件

* Java 1.8+
* ssh

### 拷贝文件到服务器

``` bash
scp hadoop-2.6.0-cdh5.15.1 hadoop@10.211.55.8:~/software/
```

### 安装：解压缩及环境配置

$解压缩至 `~/app/`$

``` bash
tar -zxvf hadoop-2.6.0-cdh5.15.1 -C ~/app/
```

hadoop 软件包常用目录名单
    bin: hadoop 客户端名单
    etc/hadoop：hadoop相关的配置文件存放目录
    sbin: 启动 hadoop相关进程的脚本

$配置 profile 文件$

``` bash
# 打开 profile 文件
vim ~/etc/profile
# 添加 HADOOP_HOME，并修改 `PATH`，具体如下
export HADOOP_HOME=/usr/hadoop/app/hadoop-2.6.0-cdh5.15.1
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
# 执行下面的命令是 profile 修改生效
source profile
```

$配置 Hadoop 的配置文件hadoop-env.sh$

``` bash
# 打开 hadoop-env.sh 文件```
# 注意在使用 `cd /etc` 命令时，总是进入系统自带 `etc`目录中
vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh
# 查找或添加下句，
# 注意该文件中 `JAVA_HOME` 的值包含 `${JAVA_HOME}` 可能无效 ，建议使用明文路径
export JAVA_HOME=/usr/java/jdk1.8.0_152
```

### 分布式部署

本次测试使用伪分布式部署方式（Pseudo-Distributed Operation）

$配置core-site.xml$

``` bash
# 打开 `core-site.xml` 文件
vim $HADOOP_HOME/etc/hadoop/core-site.xml
# 在 <configuration> 节点中洪添加如下代码
# 注意下面的 `hadoop000` 为 hostname，需在（本地及服务端） `~/etc/hosts` 文件中配置，即加入 `10.211.55.8 hadoop000`，并且应保证端口 9000 不被占用
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://hadoop000:9000</value>
</property>
```

$配置hdfs-site.xml$

``` bash
# 打开 `hdfs-site.xml` 文件
vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml
# 在 <configuration> 节点中洪添加如下代码
# 注意需在 `$HADOOP_HOME` 中创建 `tmp` 目录
# 且 `hadoop.tmp.dir` 对应的 URI 不能包含 `${}` 类型环境变量，否则导致配置无效出错 ，建议使用明文路径
<property>
    <name>dfs.replication</name>
    <value>1</value>
</property>
<property>
    <name>hadoop.tmp.dir</name>
    <value>/usr/hadoop/app/hadoop-2.6.0-cdh5.15.1/tmp</value>
</property>
```

$配置slaves$

``` bash
# 打开 `slaves` 文件，添加 `hadoop000`
vim $HADOOP_HOME/etc/hadoop/slaves
```

### 启动 HDFS

$格式化文件系统$

``` bash
# 在任意目录下执行下面的命令，注意 `hdfs` 命令在 Hadoop 的 bin 目录下
hdfs namenode -format
```

$启动 namenode 和 datanode（Start NameNode daemon and DataNode daemon）$

``` bash
# 注意下面的命令需在 hadoop 的 `sbin` 目录下执行
cd $HADOOP_HOME/bin
start-dfs.sh
```

> 🦋注意：start-dfs.sh = hadoop-daemons.sh start namenode
>                       hadoop-daemons.sh start datanode
>                       hadoop-daemons.sh start secondarynamenode

$验证$

使用 jps 命令进行验证 或者使用 在浏览器地址栏键入 http://10.211.55.8:50070，进行验证。
如使用后一种方法验证不成功，则需关闭防火墙

``` bash
# 检查防火墙状态
firewall-cmd --state
systemctl status firewalld
# 禁用或关闭防火墙
systemctl stop firewalld
```

$停止进程(namenode/datanode/secondarynamenode)$

``` bash
# 注意下面的命令需在 hadoop 的 `sbin` 目录下执行
cd $HADOOP_HOME/bin
stop-dfs.sh
```

> 🦋注意：也可以使用 `hadoop-daemons.sh stop + daemons 名称` 单独执行停止操作

## hadoop 存储机制

$复制文件到分布式文件系统$

``` bash
# 复制文件到分布式文件系统的主目录中
hdfs dfs -put hadoop-2.6.0-cdh5.15.1.tar.gz /
# 查看分布式系统主目录中存有的文件，➕参数 R 为递归查询
hdfs dfs -ls /
hdfs dfs -ls -R /
```

$浏览器及系统中查看文件存储机制$

在浏览器地址栏键入http://10.211.55.8:50070，并点击 `Utilities >> Browse the file system` 查看相关 `block` 信息。

在 $HADOOP_HOME/tmp/dfs/data/current/BP-1788419893-10.211.55.8-1557305523480/current/finalized/subdir0/subdir0 查看存储在分布式文件系统中的分块文件。

``` bash
-rw-rw-r--. 1 hadoop hadoop 134217728 5月   9 09:51 blk_1073741825
-rw-rw-r--. 1 hadoop hadoop   1048583 5月   9 09:51 blk_1073741825_1001.meta
-rw-rw-r--. 1 hadoop hadoop 134217728 5月   9 09:52 blk_1073741826
-rw-rw-r--. 1 hadoop hadoop   1048583 5月   9 09:52 blk_1073741826_1002.meta
-rw-rw-r--. 1 hadoop hadoop 134217728 5月   9 09:52 blk_1073741827
-rw-rw-r--. 1 hadoop hadoop   1048583 5月   9 09:52 blk_1073741827_1003.meta
-rw-rw-r--. 1 hadoop hadoop  31376332 5月   9 09:52 blk_1073741828
-rw-rw-r--. 1 hadoop hadoop    245135 5月   9 09:52 blk_1073741828_1004.meta

# 尝试使用 `cat >>` 命令进行文件拼接，注意拼接需按照 `block id` 有效到大的顺序进行
[hadoop@hadoop000 subdir0]$ cat blk_1073741825 >> hadoop123
[hadoop@hadoop000 subdir0]$ cat blk_1073741826 >> hadoop123
[hadoop@hadoop000 subdir0]$ cat blk_1073741827 >> hadoop123
[hadoop@hadoop000 subdir0]$ cat blk_1073741828 >> hadoop123
[hadoop@hadoop000 subdir0]$ ll
-rw-rw-r--. 1 hadoop hadoop 134217728 5月   9 09:51 blk_1073741825
-rw-rw-r--. 1 hadoop hadoop   1048583 5月   9 09:51 blk_1073741825_1001.meta
-rw-rw-r--. 1 hadoop hadoop 134217728 5月   9 09:52 blk_1073741826
-rw-rw-r--. 1 hadoop hadoop   1048583 5月   9 09:52 blk_1073741826_1002.meta
-rw-rw-r--. 1 hadoop hadoop 134217728 5月   9 09:52 blk_1073741827
-rw-rw-r--. 1 hadoop hadoop   1048583 5月   9 09:52 blk_1073741827_1003.meta
-rw-rw-r--. 1 hadoop hadoop  31376332 5月   9 09:52 blk_1073741828
-rw-rw-r--. 1 hadoop hadoop    245135 5月   9 09:52 blk_1073741828_1004.meta
-rw-rw-r--. 1 hadoop hadoop 434029516 5月   9 10:06 hadoop123

# 拼接成的文件 hadoop123 与 存入分布式文件系统前的原文件是同一个文件的副本，可以导出至本地并正常使用
```

$删除文件系统中的文件$

删除文件

``` bash
hdfs dfs -rm 文件相对路径
```

删除目录

``` bash
# 删除空目录（其下无文件或 子目录）
hdfs dfs -rmdir 空目录
# 递归删除指定目录下所有子目录
hdfs dfs -rm -r 目录
hdfs dfs -rmr 目录
```

查看

``` bash
hdfs dfs -ls /
```

## HDFS 实战：文件词频统计

使用 HDFS Java API 实现HDFS 文件系统中文件的词频统计功能
词频统计：wordcount

替代方法：MapReduce/spark

## replication policy

一般策略

1. 本 rack 的一个节点上
2. 另外一个 rack 的一个节点上
3. 与 2 相同的 rack 的拎一个节点上

---

1. 本 rack 的一个节点上
2. 本 rack 的另外一个节点上
3. 不同rack 的一个节点上

![Xnip2019-05-11_23-19-56](/assets/Xnip2019-05-11_23-19-56.png)
![Xnip2019-05-11_23-26-09](/assets/Xnip2019-05-11_23-26-09.png)

## HDFS 元数据管理

$元数据$

HDFS 的目录结构以及每个文件的 block 信息（block ID，replication sum，DataNode location）

存储位置：`~/tmp/dfs/name/current/`
元数据存储在文件中

$checkpoint 机制$
![Xnip2019-05-11_23-49-13](/assets/Xnip2019-05-11_23-49-13.png)

$safemode$

safemode处于 on 状态时，HDFS 无法执行读写操作，进过 30 秒时间，会自动转为 off 状态。

On startup, the NameNode enters a special state called Safemode. `Replication of data blocks does not occur` when the NameNode is in the Safemode state. The NameNode receives `Heartbeat` and `Blockreport` messages from the DataNodes. A Blockreport contains the list of data blocks that a DataNode is hosting. Each block has a `specified minimum number of replicas`. `A block is considered safely replicated when the minimum number of replicas of that data block has checked in with the NameNode`. After a configurable percentage of safely replicated data blocks checks in with the NameNode (**`plus an additional 30 seconds`**), the NameNode exits the Safemode state. It then determines the list of data blocks (if any) that still have fewer than the specified number of replicas. The NameNode then replicates these blocks to other DataNodes.

在启动时，NameNode进入一个名为Safemode的特殊状态。当NameNode处于Safemode状态时，不会发生数据块的复制。NameNode从DataNode接收Heartbeat和Blockreport消息。Blockreport包含DataNode托管的数据块列表。每个块都有指定的最小副本数。当使用NameNode检入该数据块的最小副本数时，会认为该块是安全复制的。在可配置百分比的安全复制数据块使用NameNode检入（再加上30秒）后，NameNode退出Safemode状态。然后，它确定仍然具有少于指定数量的副本的数据块列表（如果有）。然后，NameNode将这些块复制到其他DataNode。

## mapreduce

mapreduce优点：海量数据离线处理、易开发、易运行
缺点：无法适用于实时流式计算

![Xnip2019-05-12_16-42-56](/assets/Xnip2019-05-12_16-42-56.png)

在编程模型中需要做的工作是 `spliting -> mapping` 以及 `shuffling -> reducing` 的操作。

![Xnip2019-05-12_17-00-15](/assets/Xnip2019-05-12_17-00-15.png)

![mapreduce-job-execution-flow-1-1024x492-1](/assets/mapreduce-job-execution-flow-1-1024x492-1.jpg)

### Combiner 操作

优点：减少 IO，提升作业执行效能
缺点：适用于和积操作，对于除操作，例如，求平均数等，会使得结果失效。

![Xnip2019-05-13_17-15-06](/assets/Xnip2019-05-13_17-15-06.png)

## YARN

### 产生背景

* MapReduce1.x 存在问题 master/salve - JobTracker、TaskTracker
  * JobTracker: 单点，压力大
  * 只能够支持 MapReduce 作业，不能支持 spark 作业
* 资源利用率低下，运维成本高


![Xnip2019-05-13_23-29-19](/assets/Xnip2019-05-13_23-29-19.png)
![Xnip2019-05-13_23-32-45](/assets/Xnip2019-05-13_23-32-45.png)

The ResourceManager has two main components: **Scheduler** and **ApplicationsManager**.

`The Scheduler is responsible for allocating resources to the various running applications subject to familiar constraints of capacities, queues etc`. The Scheduler is pure scheduler in the sense that it performs no monitoring or tracking of status for the application. Also, it offers no guarantees about restarting failed tasks either due to application failure or hardware failures. The Scheduler performs its scheduling function based the resource requirements of the applications; it does so based on the abstract notion of a resource Container which incorporates elements such as memory, cpu, disk, network etc. In the first version, only memory is supported.

The Scheduler has a pluggable policy plug-in, which is responsible for partitioning the cluster resources among the various queues, applications etc. The current Map-Reduce schedulers such as the CapacityScheduler and the FairScheduler would be some examples of the plug-in.

The CapacityScheduler supports hierarchical queues to allow for more predictable sharing of cluster resources

The ApplicationsManager is responsible for accepting job-submissions, **negotiating the first container for executing the application specific ApplicationMaster** and provides the service for restarting the ApplicationMaster container on failure.

The NodeManager is the per-machine framework agent who is responsible for containers, monitoring their resource usage (cpu, memory, disk, network) and reporting the same to the ResourceManager/Scheduler.

The per-application ApplicationMaster has the responsibility of negotiating appropriate resource containers from the Scheduler, tracking their status and monitoring for progress.

---

ResourceManager有两个主要组件：Scheduler和ApplicationsManager。

Scheduler 负责根据熟悉的容量，队列等约束将资源分配给各种正在运行的应用程序。Scheduler是纯调度程序，因为它不执行应用程序状态的监视或跟踪。此外，由于应用程序故障或硬件故障，它无法保证重新启动失败的任务。Scheduler根据应用程序的资源需求执行其调度功能; 它基于资源Container的抽象概念这样做，它包含内存，cpu，磁盘，网络等元素。在第一个版本中，只支持内存。

Scheduler具有可插入的策略插件，该插件负责在各种队列，应用程序等之间对集群资源进行分区。当前的Map-Reduce调度程序（如CapacityScheduler和FairScheduler）将是插件的一些示例。

CapacityScheduler支持分层队列，以允许更可预测的群集资源共享

ApplicationsManager负责接受作业提交，**协商第一个容器以执行特定于应用程序的ApplicationMaster**，并提供在失败时重新启动ApplicationMaster容器的服务。

NodeManager是每台机器框架代理，负责容器，监视其资源使用情况（CPU，内存，磁盘，网络）并将其报告给ResourceManager / Scheduler。

每个应用程序ApplicationMaster负责从调度程序协商适当的资源容器，跟踪其状态并监视进度。

### 概述

* Yet Another Resource Negitiator
* 通用资源管理系统
* 为上层应用（mapreduce/spark/hbase）提供统一的资源管理和调度

**Apache Hadoop NextGen MapReduce (YARN)**
MapReduce has undergone a complete overhaul in hadoop-0.23 and we now have, what we call, MapReduce 2.0 (MRv2) or YARN.

The fundamental idea of MRv2 is to split up the two major functionalities of the JobTracker, resource management and job scheduling/monitoring, into separate daemons. The idea is to have a global `ResourceManager (RM)` and per-application `ApplicationMaster` (AM). An application is either a single job in the classical sense of Map-Reduce jobs or a DAG of jobs.

The ResourceManager and per-node slave, the NodeManager (NM), form the data-computation framework. **_The ResourceManager is the ultimate authority that arbitrates resources among all the applications in the system_**.

The per-application ApplicationMaster is, in effect, **_a framework specific library and is tasked with negotiating resources from the ResourceManager and working with the NodeManager(s) to execute and monitor the tasks_**.

![Xnip2019-05-13_23-48-09](/assets/Xnip2019-05-13_23-48-09.png)

### yarn 架构

Client、1-ResourceManager、n-NodeManager、n-ApplicationMaster

master/slave: RM/NM

* Client: 
  * 向 ResourceManager 提交 task，杀死 task
* ResourceManager: 
  * 处理来自 Client 的请求，启动监控 ApplicationMaster 和 NodeManager
  * 对系统中全部 application 的资源使用具有最终的裁决权利
  * 且集群中统一时刻对外提供服务的只有一个（备用除外）
* ApplicationMaster: 
  * 向 ResourceManager 申请资源用于在 NodeManager 上执行 task
  * 为每个 task 向 ResourceManager 申请资源（container）
  * 每个 application 对应一个 ApplicationMaster
  * 数据切分
  * 与 NodeManager 通信
* NodeManager: 
  * 接收来自 ResourceManager 的请求，并执行 Task
  * 处理来自 ApplicationMaster 的命令
  * 向 ResourceManager 发送心跳信息、任务执行情况、node status
* container: 任务的运行抽象
  * memory/cpu
  * task 在 container 中运行
  * **可以运行 ApplicationMaster**，也可以运行具体的 MapReduce 或者 task

yarn 的执行流程

![Xnip2019-05-14_12-10-47](/assets/Xnip2019-05-14_12-10-47.png)

### yarn 执行异常处理

$异常：$
![Xnip2019-05-14_20-12-22](/assets/Xnip2019-05-14_20-12-22.png)

$解决方案：$
![Xnip2019-05-14_20-13-01](/assets/Xnip2019-05-14_20-13-01.png)

$原因$
![Xnip2019-05-14_20-13-13](/assets/Xnip2019-05-14_20-13-13.png)
再关闭重启 HDFS 和 YARN 服务。

### 自定义 MR task 提交到 YARN 上的步骤

1. 打包成 jar 包，mvn clean package -DskipTests
2. 把上面的 jar 文件传入服务器任意位置，并且把输入文件传入服务器 HDFS 指定位置
3. 执行作业 hadoop jar xxx 完整类名 参数0 参数1
4. 在 YARN UI（8088）以及输出目录查看输出文件

## 电商项目实战

$步骤$

* 用户日志分析
* 电商常用术语
* 项目需求
* 数据处理流程及技术架构
* 需求实现
* 提交到服务器执行
* 扩展

### 用户日志

每次的访问行为，点击，搜索、行为轨迹等操作，
历史行为数据 <-- 历史订单数据

---> 推荐

$采集用户日志的目的$

1. 推荐
2. 页面布局安排

$用户行为日志的生成渠道$

1. NGINX
2. 局部 ajax 请求

$原始日志字段说明$

* 第二个字段：URL
* 第十四字段：IP
* 第十八字段：日志产生时间

字段解析：
    IP -> 地市：国家、省市、地区
    url -> 页面 id

$用户行为日志分析的意义$

引流

$项目需求$

* 统计页面浏览量 PageView
* 统计各省份的浏览量
* 统计页面的访问量 Page ID

$数据处理流程和技术架构$

对日志的处理方式选择

* MapReduce
* hive

![Xnip2019-05-16_21-24-33](/assets/Xnip2019-05-16_21-24-33.png)

### 服务器上运行作业

![Xnip2019-05-17_23-49-48](/assets/Xnip2019-05-17_23-49-48.png)

大数据处理完的数据一般存放在 HDFS 上，至此为止，或者作进一步存在数据库（sqoop），并进行前端展示

### 扩展

* 使用 userAgent工具类解析访问终端信息，并统计
* 引流统计
* 同 sessionID 计算访问步长，从而统计用户黏性
* 引流前的字段，耗费流量大小
* etl 优化
* 热集群-冷集群-对象存储
* etl 存储方式转换为列式存储

6.20~6.21 节

## 数据仓库 hive

### 背景

* MapReduce 编程的不便性
* 利用关系型数据库的便利
* HDFS 上的数据并没有 schema 的概念

 1. 由 Facebook 开源，用来处理海量结构化日志的统计计算。
 2. 构建在 Hadoop 之上的数据仓库
 3. hive 提供SQL查询语言：HQL
 4. 底层支持多种不同执行引擎，（MapReduce 是其中的一种，）

Hive 的底层执行引擎：MapReduce Tez Spark

Hive 优点：

* sql 简单易上手
* 为超大数据集设计的计算和扩展能力
* 统一元数据管理：
  * hive 数据存储在 HDFS 上，元数据（记录数据的数据）信息存放在 MySQL 上 
  * SQL on Hadoop：Hive Spark SQL Impala (互通)

hive -> SQL query

### 体系架构

    client: shell thrift/jdbc(server/jdbs) webui(hue/zeppelin)
    metastore: 存放在 MySQL 上
               database -> name owner location
               table -> name owner location column type/name
    Diver: sql parser -> query optimizer -> phsyical plan -> serdes udfs/execution
    Mapreduce
    HDFS
![Xnip2019-05-22_16-13-37](/assets/Xnip2019-05-22_16-13-37.png)

### Hive 部署架构

$测试环境$

![Xnip2019-05-22_16-28-37](/assets/Xnip2019-05-22_16-28-37.png)

$生产环境$

![Xnip2019-05-22_16-33-28](/assets/Xnip2019-05-22_16-33-28.png)

### hive 和 RDBMS 的区别

* SQL 语言形式相似，前者多用在离线处理上，处理速度比较慢，后者处理速度较快
* 支持集群处理，但是 hive 的集群处理部署在廉价的及其上，可以处理极大数据集，RDBMS 部署在高昂的机器上，处理数据集群较小
* 多支持分布式处理

### hive 安装部署

7.9 节

1. 下载
2. 解压：tar -zxvh  -C ~/app/
3. 向 profile 中添加环境变量
4. 配置 hive-env.sh，添加 HADOOP_HOME
5. 配置 hive-site.xml
6. 拷贝 MySQL driver 5.1.27 到$HIVE_HOME/lib
7. 安装 MySQL 数据库（安装未成功，延后）
   1. https://www.cnblogs.com/julyme/p/5969626.html 

hive-site.xml 文件

``` xml
<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
<property>
  <name>javax.jdo.option.ConnectionURL</name>
  <value>jdbc:mysql://hadoop000:3306/hadoop_hive?createDatabaseIfNotExist=true</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionDriverName</name>
  <value>com.mysql.jdbc.Driver</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionUserName</name>
  <value>root</value>
</property>

<property>
  <name>javax.jdo.option.ConnectionPassword</name>
  <value>root</value>
</property>
</configuration>
```

``` bash
# 登入 MySQL
mysql -uroot -proot

# 显示数据库，
show databases;

# 启动 hive
# 使用 `hive` 或者 `beeline`
cd $HIVE_HOME/bin/
hive
beeline

# 创建 test-db 数据库
hive> create database test_db;

# 显示数据库，此时新增了名为 `hadoop_hive` 的数据
# 该数据库中存放的是 **元数据信息**
show databases;

# 使用下面的命令查看数据库 hadoop_hive 中的 table
use hadoop_hive;
show tables;

# 其中有一个 名为 DBS 的表，使用下面的命令可以显示其内容
# 里面有一个 名为 default 的数据库和一个之前新建的 名为 test_db 数据库
select * from DBS \G;

# 在数据库 test_db 下创建名为 helloworld 的表
hive> use test_db;
hive> show tables;
hive> create table helloworld(id int, name string) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';
hive> show tables;
# 以文本的形式向表中添加记录
hive> load data local inpath '/home/hadoop/data/helloworld.txt' into table helloworld;

# 查看表 helloworld 中的数据
hive> select * from helloworld;

# 使用下面的命令统计 表中的记录数，会产生 MapReduce task，可以在 yarn 网址上查看
hive> select count(1) from helloworld;
```

### Hive DDL

DDL：Hive Data Definition Language

> create、delete、alter...

Hive数据抽象/结构

* database     HDFS一个目录
  * table    HDFS一个目录
    * data  文件
      * partition 分区表  HDFS一个目录
        * data  文件
        * bucket  分桶   HDFS一个文件

$创建数据库$

``` sql
CREATE (DATABASE|SCHEMA) [IF NOT EXISTS] database_name
  [COMMENT database_comment]
  [LOCATION hdfs_path]
  [WITH DBPROPERTIES (property_name=property_value, ...)];

CREATE DATABASE IF NOT EXISTS hive;

CREATE DATABASE IF NOT EXISTS hive2 LOCATION '/test/location';

CREATE DATABASE IF NOT EXISTS hive3 
WITH DBPROPERTIES('creator'='pk');

-- 查看 creator 信息
hive> desc database hive;
hive> desc database extended hive;

-- 查看当前在哪个 database 上进行操作，前句显示属性值，后句赋值给相关属性赋值
hive> set hive.cli.print.current.db
hive> set hive.cli.print.current.db = true

-- 清屏
hive> !clear

-- 删除 database，删除非空表需要添加 `CASCADE`
hive> drop database database_name
hive> drop database database_name CASCADE
hive> show database like 'hive*'

```

$创建表$

``` sql
-- 使用 default database
hive> use default;
hive> CREATE TABLE emp(
  empno int,
  ename string,
  job string,
  mgr int,
  hiredate string,
  sal double,
  comm double,
  deptno int
) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' LINES TERMINATED BY ' ';

-- 查看表结构
hive> desc emp;

-- 查看表的存储信息
hive> desc extended emp;
hive> desc formatted emp;

-- 将文件中的数据注入表 emp 中
hive> LOAD DATA LOCAL INPATH '/home/hadoop/data/emp.txt' OVERWRITE INTO TABLE emp;

-- 查看表 emp 的内容
hive> select * from emp;

-- 查看 warehouse 中的 emp 表
$ hadoop fs -ls /user/hive/warehouse/emp
-- 输出为：/user/hive/warehouse/emp/emp.txt
-- 即就是表 emp 名为 emp.txt

-- 修改表表名称
ALTER TABLE table_name RENAME TO new_table_name;
```






### hive 数据抽象、结构

---

HDFS上的文件并没有schema的概念

* schema

Hive底层执行引擎支持：MR/Tez/Spark

统一元数据管理：

* Hive数据是存放在HDFS
* 元数据信息(记录数据的数据)是存放在MySQL中
* SQL on Hadoop： Hive、Spark SQL、impala....

Hive体系架构
	client：shell、thrift/jdbc(server/jdbc)、WebUI(HUE/Zeppelin)
	metastore：==> MySQL
		database：name、location、owner....
		table：name、location、owner、column name/type ....




/user/hive/warehouse是Hive默认的存储在HDFS上的路径

``` sql

LOAD DATA [LOCAL] INPATH 'filepath' [OVERWRITE] INTO TABLE tablename [PARTITION (partcol1=val1, partcol2=val2 ...)]

LOCAL：本地系统，如果没有local那么就是指的HDFS的路径
OVERWRITE：是否数据覆盖，如果没有那么就是数据追加

LOAD DATA LOCAL INPATH '/home/hadoop/data/emp.txt' OVERWRITE INTO TABLE emp;

LOAD DATA INPATH 'hdfs://hadoop000:8020/data/emp.txt' INTO TABLE emp;

INSERT OVERWRITE LOCAL DIRECTORY '/tmp/hive/'
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'
select empno,ename,sal,deptno from emp;
```

聚合： max/min/sum/avg

分组函数： group by

``` sql
-- 求每个部门的平均工资
-- 出现在select中的字段，如果没有出现在聚合函数里，那么一定要实现在group by里
select deptno, avg(sal) from emp group by deptno;

-- 求每个部门、工作岗位的平均工资
select deptno,job avg(sal) from emp group by deptno,job;


-- 求每个部门的平均工资大于2000的部门
select deptno, avg(sal) avg_sal from emp group by deptno where avg_sal>2000;

-- 对于分组函数过滤要使用having
select deptno, avg(sal) avg_sal from emp group by deptno having avg_sal>2000;
```

join ： 多表

``` sql
emp
dept

CREATE TABLE dept(
deptno int,
dname string,
loc string
) ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t';

LOAD DATA LOCAL INPATH '/home/hadoop/data/dept.txt' OVERWRITE INTO TABLE dept;

explain EXTENDED
select e.empno,e.ename,e.sal,e.deptno,d.dname from emp e join dept d
on e.deptno=d.deptno;
```

---
